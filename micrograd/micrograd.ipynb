{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "  def __init__(self, value: float) -> None:\n",
    "    self.name: str = \"\"\n",
    "    self.value: float = value\n",
    "\n",
    "    self.parents: tuple[Node, Node] = (None, None)\n",
    "    self.gradient: float = 0\n",
    "    self._backward: function = lambda *args: None\n",
    "\n",
    "    self.visited = False # makes dfs more efficient\n",
    "  \n",
    "  def __add__(self, other: Node | float) -> Node:\n",
    "    other = other if type(other) is Node else Node(other)\n",
    "    child = Node(self.value + other.value)\n",
    "    child.parents = (self, other)\n",
    "    def _backward(): # accumulates gradients of parents\n",
    "      self.gradient += 1 * child.gradient # local derivative * global derivative\n",
    "      other.gradient += 1 * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def __radd__(self, other: Node | float) -> Node:\n",
    "    return self.__add__(other)\n",
    "  \n",
    "  def __sub__(self, other: Node | float) -> Node:\n",
    "    other = other if type(other) is Node else Node(other)\n",
    "    child = Node(self.value - other.value)\n",
    "    child.parents = (self, other)\n",
    "    def _backward():\n",
    "      self.gradient += 1 * child.gradient\n",
    "      other.gradient += -1 * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def __mul__(self, other: Node | float) -> Node:\n",
    "    other = other if type(other) is Node else Node(other)\n",
    "    child = Node(self.value * other.value)\n",
    "    child.parents = (self, other)\n",
    "    def _backward():\n",
    "      self.gradient += other.value * child.gradient\n",
    "      other.gradient += self.value * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "\n",
    "  def topological_sort(self) -> list[Node]: # reverse dfs\n",
    "    dfs_sort: list[Node] = []\n",
    "    def dfs(node: Node) -> None:\n",
    "      if node.parents[0]:\n",
    "        dfs(node.parents[0])\n",
    "      if node.parents[1]:\n",
    "        dfs(node.parents[1])\n",
    "      if not node.visited:\n",
    "        dfs_sort.append(node); node.visited = True\n",
    "    dfs(self); return list(reversed(dfs_sort))\n",
    "\n",
    "  def backward(self) -> None:\n",
    "    self.gradient = 1 # derivative w.r.t to this node\n",
    "    for node in self.topological_sort():\n",
    "      node._backward()\n",
    "      print(node.name, node.value, node.gradient)\n",
    "\n",
    "  def zero_grad(self) -> None:\n",
    "    self.grad = 0\n",
    "    self.visited = False\n",
    "\n",
    "  def __repr__(self) -> str:\n",
    "    return f\"Scalar(name={self.name}, value={self.value})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l 43 1\n",
      "h 40 1\n",
      "g 20 2\n",
      "d 4 10\n",
      "f 5 8\n",
      "c -1 8\n",
      "e 6 8\n",
      "b 2 24\n",
      "a 3 17\n"
     ]
    }
   ],
   "source": [
    "a = Node(3); a.name = \"a\"\n",
    "b = Node(2); b.name = \"b\"\n",
    "c = Node(-1); c.name = \"c\"\n",
    "d = Node(4); d.name = \"d\"\n",
    "e = a * b; e.name = \"e\"\n",
    "f = e + c; f.name = \"f\"\n",
    "g = f * d; g.name = \"g\"\n",
    "h = g + g; h.name = \"h\"\n",
    "l = h + a; l.name = \"l\"\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scalar(name=l, value=43), Scalar(name=h, value=40), Scalar(name=g, value=20), Scalar(name=d, value=4), Scalar(name=f, value=5), Scalar(name=c, value=-1), Scalar(name=e, value=6), Scalar(name=b, value=2), Scalar(name=a, value=3)]\n"
     ]
    }
   ],
   "source": [
    "dfs_traversal = []\n",
    "def dfs(node: Node) -> Node: \n",
    "  if node.parents[0]:\n",
    "    dfs(node.parents[0])\n",
    "  if node.parents[1]:\n",
    "    dfs(node.parents[1])\n",
    "\n",
    "  if not node.visited:\n",
    "    dfs_traversal.append(node)\n",
    "    node.visited = True\n",
    "\n",
    "dfs(l)\n",
    "print(list(reversed(dfs_traversal)))\n",
    "# only call a node's _backward() when gradients have been fully accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
