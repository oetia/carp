{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gpu = cp.array([1, 2, 3])\n",
    "x_cpu = x_gpu.get()\n",
    "type(x_cpu)\n",
    "type(x_gpu)\n",
    "\n",
    "# lets keep things on purely on the cpu for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "  def __init__(self, list: list) -> None:\n",
    "    self.name: str = \"\"\n",
    "    self.values: np.array = np.array(list)\n",
    "    self.parents: tuple[Tensor, Tensor] = (None, None)\n",
    "    self.gradient: np.array = np.zeros_like(self.values)\n",
    "    self._backward: function = lambda *args: None\n",
    "    self.visited = False\n",
    "\n",
    "  def __add__(self, other: Tensor) -> Tensor:\n",
    "    child = Tensor(self.values + other.values)\n",
    "    child.parents = (self, other)\n",
    "    def _backward() -> None:\n",
    "      self.gradient = 1 * child.gradient\n",
    "      other.gradient = 1 * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def __mul__(self, other: Tensor) -> Tensor:\n",
    "    child = Tensor(self.values + other.values)\n",
    "    child.parents = (self, other)\n",
    "    def _backward() -> None:\n",
    "\n",
    "      self.gradient = other.values * child.gradient # mistake made using Tensor object instead of tensor value\n",
    "      other.gradient = self.values * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def topological_sort(self) -> list[Tensor]:\n",
    "    dfs_sort: list[Tensor] = []\n",
    "    def dfs(node: Tensor):\n",
    "      if node.parents[0]:\n",
    "        dfs(node.parents[0])\n",
    "      if node.parents[1]:\n",
    "        dfs(node.parents[1])\n",
    "      if not node.visited:\n",
    "        dfs_sort.append(node); node.visited = True\n",
    "    dfs(self); return list(reversed(dfs_sort))\n",
    "\n",
    "  def backward(self):\n",
    "    self.gradient = np.ones_like(self.values) # gradient w.r.t self\n",
    "    for node in self.topological_sort():\n",
    "      node._backward()\n",
    "      print(node)\n",
    "\n",
    "  def zero_grad(self):\n",
    "    self.gradient = np.zeros_like(self.values)\n",
    "  \n",
    "  def __repr__(self) -> str:\n",
    "    return f\"{self.name}: {self.values} : {self.gradient}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: [ 7 14 21] : [1 1 1]\n",
      "e: [ 6 12 18] : [1 2 3]\n",
      "c: [3 6 9] : [1 2 3]\n",
      "d: [3 6 9] : [1 2 3]\n",
      "b: [2 4 6] : [1 4 9]\n",
      "a: [1 2 3] : [ 2  8 18]\n"
     ]
    }
   ],
   "source": [
    "a = Tensor([1, 2, 3]); a.name = \"a\"\n",
    "b = Tensor([2, 4, 6]); b.name = \"b\"\n",
    "c = Tensor([3, 6, 9]); c.name = \"c\"\n",
    "d = a * b; d.name = \"d\"\n",
    "e = d + c; e.name = \"e\"\n",
    "f = e * a; f.name = \"f\"\n",
    "f.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
