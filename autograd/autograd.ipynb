{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gpu = cp.array([1, 2, 3])\n",
    "x_cpu = x_gpu.get()\n",
    "type(x_cpu)\n",
    "type(x_gpu)\n",
    "\n",
    "# lets keep things on purely on the cpu for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "  def __init__(self, list: list) -> None:\n",
    "    self.name: str = \"\"\n",
    "    self.values: np.array = np.array(list)\n",
    "    self.parents: tuple[Tensor, Tensor] = (None, None)\n",
    "    self.gradient: np.array = np.zeros_like(self.values)\n",
    "    self._backward: function = lambda *args: None\n",
    "    self.visited = False\n",
    "\n",
    "  def __add__(self, other: Tensor) -> Tensor:\n",
    "    child = Tensor(self.values + other.values)\n",
    "    child.parents = (self, other)\n",
    "    def _backward() -> None:\n",
    "      self.gradient += 1 * child.gradient\n",
    "      other.gradient += 1 * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def __mul__(self, other: Tensor) -> Tensor:\n",
    "    child = Tensor(self.values * other.values)\n",
    "    child.parents = (self, other)\n",
    "    def _backward() -> None:\n",
    "      self.gradient += other.values * child.gradient # mistake made using Tensor object instead of tensor value\n",
    "      other.gradient += self.values * child.gradient # keep in mind whether dealing with object object.values or object.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def sum(self) -> Tensor:\n",
    "    child = Tensor([self.values.sum()])\n",
    "    child.parents = (self, None)\n",
    "    def _backward() -> None:\n",
    "      self.gradient += np.ones_like(self.values) * child.gradient\n",
    "    child._backward = _backward\n",
    "    return child\n",
    "  \n",
    "  def topological_sort(self) -> list[Tensor]:\n",
    "    dfs_sort: list[Tensor] = []\n",
    "    def dfs(node: Tensor):\n",
    "      if node.parents[0]:\n",
    "        dfs(node.parents[0])\n",
    "      if node.parents[1]:\n",
    "        dfs(node.parents[1])\n",
    "      if not node.visited:\n",
    "        dfs_sort.append(node); node.visited = True\n",
    "    dfs(self); return list(reversed(dfs_sort))\n",
    "\n",
    "  def backward(self):\n",
    "    self.gradient = np.ones_like(self.values) # gradient w.r.t self\n",
    "    for node in self.topological_sort():\n",
    "      node._backward()\n",
    "      print(node)\n",
    "\n",
    "  def zero_grad(self):\n",
    "    self.gradient = np.zeros_like(self.values)\n",
    "    self.visited = False\n",
    "  \n",
    "  def __repr__(self) -> str:\n",
    "    return f\"{self.name}: {self.values} : {self.gradient}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2]) * np.array([2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l: [114] : [1]\n",
      "f: [ 5 28 81] : [1 1 1]\n",
      "e: [ 5 14 27] : [1 2 3]\n",
      "c: [3 6 9] : [1 2 3]\n",
      "d: [ 2  8 18] : [1 2 3]\n",
      "b: [2 4 6] : [1 4 9]\n",
      "a: [1 2 3] : [ 7 22 45]\n"
     ]
    }
   ],
   "source": [
    "a = Tensor([1, 2, 3]); a.name = \"a\"\n",
    "b = Tensor([2, 4, 6]); b.name = \"b\"\n",
    "c = Tensor([3, 6, 9]); c.name = \"c\"\n",
    "d = a * b; d.name = \"d\"\n",
    "e = d + c; e.name = \"e\"\n",
    "f = e * a; f.name = \"f\"\n",
    "l = f.sum(); l.name = \"l\"\n",
    "l.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  8., 18.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([ 5., 14., 27.], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([ 5., 28., 81.], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(114., dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# comparing with pytorch\n",
    "import torch\n",
    "a = torch.tensor([1, 2, 3], dtype=float, requires_grad=True)\n",
    "b = torch.tensor([2, 4, 6], dtype=float, requires_grad=True)\n",
    "c = torch.tensor([3, 6, 9], dtype=float, requires_grad=True)\n",
    "d = a * b; d.retain_grad()\n",
    "e = d + c; e.retain_grad()\n",
    "f = e * a; f.retain_grad()\n",
    "l = f.sum(); l.retain_grad()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7., 22., 45.], dtype=torch.float64)\n",
      "tensor([1., 4., 9.], dtype=torch.float64)\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n",
      "tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensors = [a, b, c, d, e, f, l]\n",
    "for tensor in tensors:\n",
    "  print(tensor.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
